{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Industry Consulting Firm\n",
    "July 16, 2019<br>\n",
    "Mindy & Ngoc, Helper Functions\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import pingouin    # welch F test\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DataFrame Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(df, col1, col2, sep):\n",
    "    '''\n",
    "    input:\n",
    "    df: dataframe to use\n",
    "    col1 and col2 (use col2 to split)\n",
    "    return:\n",
    "    a df table with col1 as common col and col2 split into multiple rows\n",
    "    '''\n",
    "    series = [pd.Series(row[col1], row[col2].split(sep))\n",
    "              for _, row in df.iterrows()]\n",
    "    table = pd.concat(series).reset_index()\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitgroups(df, colname, names):\n",
    "    '''\n",
    "    df: dataframe to split the groups \n",
    "    colname: name of the column, a string\n",
    "    names: criteria a list of string to split column of interest\n",
    "    return: separate dfs, num is length of names, used for split into DC, MD, VA\n",
    "    '''\n",
    "    dfs = []\n",
    "    for i in range(len(names)):\n",
    "        mask = df[colname] == names[i]\n",
    "        dfs.append(df[mask].reset_index())\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into high price and low price\n",
    "def samples(df, colname, criteria, value):\n",
    "    '''\n",
    "    df: a dataframe\n",
    "    colname: colname of interest for split \n",
    "    criteria: an int for filter for colname\n",
    "    value: colname for actual comparsion \n",
    "    return 2 samples of 1 day numpy array, data1 uses mask, data2 complement mask\n",
    "    '''\n",
    "    mask = df[colname] >= criteria\n",
    "    data1 = df[mask].reset_index()[value]\n",
    "    data2 = df[~mask].reset_index()[value]\n",
    "    return (data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_transform(datas, group_names, colname):\n",
    "    '''\n",
    "    datas: a list of data for comparision \n",
    "    group_names: a list of strings with group names, datas order should be same as group_names\n",
    "    colname: string, the category to compare \n",
    "    return tukeyhsd table result and stacked table \n",
    "    create stacked dataframe for tukey_hsd and welch F test\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(group_names)):\n",
    "        df[group_names[i]] = datas[i]\n",
    "    stacked_df = df.stack().reset_index()\n",
    "    stacked_df = stacked_df.rename(\n",
    "        columns={'level_0': 'id', 'level_1': 'state', 0: colname})\n",
    "    return stacked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Inferential Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferentialStatisticsHelperFunctions():\n",
    "    '''\n",
    "    a class for perform inferential statistics \n",
    "    '''\n",
    "\n",
    "    def normality_tests(self, groups_data, group_name, metric_list):\n",
    "        '''\n",
    "        groups_data: a list of dataframes for comparision\n",
    "        group_name: name for the dataframe in groups_data\n",
    "        metric_list: a list of metrics, such as rating \n",
    "        return: df of normal or not normal \n",
    "        '''\n",
    "        df_dict = {}\n",
    "        for i in range(len(group_name)):\n",
    "            df_dict[group_name[i]] = {}\n",
    "            for metric in metric_list:\n",
    "                # 0.05 is alpha level\n",
    "                if stats.normaltest(groups_data[i][metric])[1] > 0.05:\n",
    "                    df_dict[group_name[i]][metric] = 'normal'\n",
    "                else:\n",
    "                    df_dict[group_name[i]][metric] = 'not normal'\n",
    "        return pd.DataFrame(df_dict)\n",
    "\n",
    "    def variance_tests(self, groups_data):\n",
    "        '''\n",
    "        groups_data: a list data of 1 day \n",
    "        return: test equal variance or not using stats.levene test \n",
    "        '''\n",
    "        # alpha is 0.05\n",
    "        if stats.levene(*groups_data)[1] > 0.05:\n",
    "            return 'equal variance holds'\n",
    "        else:\n",
    "            return 'not equal variance '\n",
    "\n",
    "    def bootstrap(self, sample, n):\n",
    "        '''\n",
    "        input:\n",
    "        sample: sample to use (1-d array)\n",
    "        n: desired size of the sampling sample (int)\n",
    "        return:\n",
    "        a list of n random numbers drawn from the input sample with replacement\n",
    "        '''\n",
    "        return np.random.choice(sample, size=n, replace=True)\n",
    "\n",
    "    def sampling(self, sample, n, num):\n",
    "        '''\n",
    "        input:\n",
    "        sample: sample to use (1-d array)\n",
    "        n: desired size of the sampling sample (int)\n",
    "        num: desired size of the sampling method\n",
    "        return:\n",
    "        a list of num sampling means\n",
    "        '''\n",
    "        sample_means = []\n",
    "        for i in range(num):\n",
    "            sample_means.append(self.bootstrap(sample, n).mean())\n",
    "        return sample_means\n",
    "\n",
    "    def sample_category(self, samples, n, num, feature):\n",
    "        '''\n",
    "        input:\n",
    "        samples: a dataframe \n",
    "        feature: column name for the dataframe to sample from \n",
    "        n: desired size of the sampling sample (int)\n",
    "        num: desired size of the sampling method\n",
    "        return:\n",
    "        a list of num of samples[feature] means \n",
    "        '''\n",
    "        return self.sampling(samples[feature], n, num)\n",
    "\n",
    "    def one_way_anova(self, groups_data):\n",
    "        '''\n",
    "        groups_data: a list data of 1 day \n",
    "        return: perform stats.f_oneway to check if there are differences present \n",
    "        '''\n",
    "        # alpha is 0.05\n",
    "        if stats.f_oneway(*groups_data)[1] > 0.05:\n",
    "            return 'fail to reject Null Hypothesis'\n",
    "        else:\n",
    "            return 'reject Null Hypothesis'\n",
    "\n",
    "    def tukey_hsd(self, stacked_df, colname):\n",
    "        '''\n",
    "        stacked_df: from table_transform, a stacked df \n",
    "        colname: string, the category to compare \n",
    "        return tukeyhsd table result and stacked table \n",
    "        set up tukey hsd for post anova with significance\n",
    "        '''\n",
    "        MultiComp = MultiComparison(stacked_df[colname],\n",
    "                                    stacked_df['state'])\n",
    "        return MultiComp.tukeyhsd().summary()\n",
    "\n",
    "    def welch_f_test(self, stacked_df, dependentvar, groupname):\n",
    "        '''\n",
    "        stacked_data: a dataframe from table_transform_function\n",
    "        dependentvar: value to compare \n",
    "        groupname: names of group to split \n",
    "        return: perform welch F test to check if there are differences present \n",
    "        '''\n",
    "        # alpha is 0.05\n",
    "        p_value = pingouin.welch_anova(\n",
    "            dependentvar, groupname, stacked_df)['p-unc'][0]\n",
    "        if p_value > 0.05:\n",
    "            return 'fail to reject Null Hypothesis'\n",
    "        else:\n",
    "            return 'reject Null Hypothesis'\n",
    "\n",
    "    def chisquare_test(self, df, category1, category2):\n",
    "        '''\n",
    "        df: dataframe with data to compare , pd dataframe\n",
    "        category1: categorical variable one, string \n",
    "        category2: categorical variable two , string \n",
    "        return chi square independence result \n",
    "        '''\n",
    "        # create counts for chisquare test\n",
    "        counts = df.groupby([category1, category2]).size().reset_index()\n",
    "        # make into proper format for chisquare test\n",
    "        chi_table = counts.pivot(index=category1, columns=category2, values=0)\n",
    "        # turn into numpy array\n",
    "        chi_array = np.array(chi_table)\n",
    "        if stats.chi2_contingency(chi_array)[1] > 0.05:\n",
    "            return 'fail to reject Null Hypothesis'\n",
    "        else:\n",
    "            return 'reject Null Hypothesis'\n",
    "\n",
    "    def welch_ttest(self, groups_data, group_name):\n",
    "        '''\n",
    "        groups_data: a list data of 1 day \n",
    "        group_name: string for groups_data, a list of string\n",
    "        return: perform stats.ttest_ind, welch to check if there are differences in mean \n",
    "        '''\n",
    "        # alpha is 0.05\n",
    "        result = stats.ttest_ind(*groups_data, equal_var=False)\n",
    "        if result[1] > 0.05:\n",
    "            return 'fail to reject Null Hypothesis'\n",
    "        elif result[0] > 0:\n",
    "            return f'{group_name[0]} appears to statistically perform better than {group_name[1]}'\n",
    "        else:\n",
    "            return f'{group_name[0]} appears to statistiscally perform worse than {group_name[1]}'\n",
    "\n",
    "    def price_welcht(self, DF, colname, criteria, metric, n, num, group_name):\n",
    "        '''\n",
    "        DF: pd dataframe\n",
    "        colname: colname to split data, a string\n",
    "        criteria: a number, criteria for split\n",
    "        metric: a string, review count or rating \n",
    "        n: num of samples for sample mean\n",
    "        num: num of iteration for sample means\n",
    "        group_name: string for groups_data, a list of string\n",
    "        return: welcht test result \n",
    "        '''\n",
    "        price_splits = samples(DF, colname, 2, metric)\n",
    "        price_high = price_splits[0]\n",
    "        price_low = price_splits[1]\n",
    "        # sampling\n",
    "        high_means = np.array(self.sampling(price_high, n, num))\n",
    "        low_means = np.array(self.sampling(price_low, n, num))\n",
    "        return self.welch_ttest([high_means, low_means], group_name)\n",
    "\n",
    "    def top_two_cuisines(self, df, metric):\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Total number of reviews for each cuisine:\n",
    "        sum_review_by_cuisine = df.groupby(\"cuisine\")[metric].sum()\n",
    "        # Total number of restaurants for each cuisine:\n",
    "        count_by_cuisine = df.groupby(\"cuisine\")[metric].count()\n",
    "        # \"Standardized\" number of reviews for each cuisine:\n",
    "        std_sum_review_by_cuisine = sum_review_by_cuisine / count_by_cuisine\n",
    "        print(std_sum_review_by_cuisine.sort_values(\n",
    "            ascending=False).head(2).index)\n",
    "\n",
    "    def get_cuisine(self, df, cuisine):\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        new_df = df[df.cuisine == cuisine]\n",
    "        new_df.reset_index(inplace=True, drop=True)\n",
    "        df_review_count = new_df.review_count\n",
    "        df_rating = new_df.rating\n",
    "        return df_review_count, df_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plothist(join_df, df):\n",
    "    '''\n",
    "    join_df: dataframe containing all DC, MD, VA\n",
    "    df: a list of separate dataframes, DC, MD, VA\n",
    "    return a 2 by 2 histogram plot for comparision \n",
    "    '''\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.add_subplot(221)\n",
    "    plt.hist(join_df.price, label='Metroplex',\n",
    "             color='red', bins=4, density=True)\n",
    "    plt.legend()\n",
    "    fig.add_subplot(222)\n",
    "    plt.hist(df[0].price, label='DC', color='blue', bins=4, density=True)\n",
    "    plt.legend()\n",
    "    fig.add_subplot(223)\n",
    "    plt.hist(df[1].price, label='MD', color='green', bins=4, density=True)\n",
    "    plt.legend()\n",
    "    fig.add_subplot(224)\n",
    "    plt.hist(df[2].price, label='VA', color='purple', bins=4, density=True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(array1, array2, labels, featurename):\n",
    "    '''\n",
    "    array1: 1 d array\n",
    "    array2: 1 d array\n",
    "    labels: a list of string for label array1 and array2\n",
    "    return: histogram plot with 2 plots on the same ax\n",
    "    '''\n",
    "    sns.distplot(array1, label=labels[0], color='red')\n",
    "    sns.distplot(array2, label=labels[1], color='blue')\n",
    "    plt.ylabel('probability density', fontdict={'size': 10})\n",
    "    plt.title(f'{featureaname} Probability Density Plot for'\n",
    "              f'{labels[0]} and {labels[1]}', fontdict={\n",
    "                  'size': 12})\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
