{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import pingouin\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import location and price df\n",
    "df_location_price = pd.read_pickle('data/yelp_price_location.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad|Seafood|American (Traditional)</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>372</td>\n",
       "      <td>38.997397</td>\n",
       "      <td>-77.026797</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pizza|American (New)|Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>192</td>\n",
       "      <td>38.919506</td>\n",
       "      <td>-77.224311</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             categories price  rating  review_count  \\\n",
       "0  Salad|Seafood|American (Traditional)     2     3.5           372   \n",
       "1            Pizza|American (New)|Salad     2     3.5           192   \n",
       "\n",
       "         Lat        Lon state  \n",
       "0  38.997397 -77.026797    MD  \n",
       "1  38.919506 -77.224311    VA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location_price.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at review count and rating vs state first split into 3 groups\n",
    "# DC, VA, MD\n",
    "DC = df_location_price[df_location_price.state == 'DC'][[\n",
    "    'state', 'review_count', 'rating']].reset_index()\n",
    "MD = df_location_price[df_location_price.state == 'MD'][[\n",
    "    'state', 'review_count', 'rating']].reset_index()\n",
    "VA = df_location_price[df_location_price.state == 'VA'][[\n",
    "    'state', 'review_count', 'rating']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for anova assumption:\n",
    "# Normality:\n",
    "# Caveat to this is, if group sizes are equal, the F-statistic is robust to violations of normality\n",
    "# Homogeneity of variance\n",
    "# Same caveat as above, if group sizes are equal, the F-statistic is robust to this violation\n",
    "# Independent observations (assume independent most of the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormaltestResult(statistic=1457.8930410979126, pvalue=0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normality test \n",
    "stats.normaltest(DC.rating)\n",
    "stats.normaltest(MD.rating)\n",
    "stats.normaltest(VA.rating)\n",
    "stats.normaltest(DC.review_count)\n",
    "stats.normaltest(MD.review_count)\n",
    "stats.normaltest(VA.review_count)\n",
    "# not normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generate 100 samples for 100000 times to generate normal distributions \n",
    "# for both review count and rating \n",
    "def boostrap_sample(samples, n):\n",
    "    return np.random.choice(samples, size = n, replace = True )\n",
    "# generate sample means\n",
    "def sampling(samples, n, num):\n",
    "    sample_means = []\n",
    "    for i in range(num):\n",
    "        sample_means.append(boostrap_sample(samples, n).mean())\n",
    "    return sample_means\n",
    "def sample_category(samples,n,num, feature):\n",
    "    return sampling(samples[feature], n, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked dataframe for tukey_hsd and welch F test\n",
    "def table_transform(datas, group_names, colname):\n",
    "    '''\n",
    "    datas: a list of data for comparision \n",
    "    group_names: a list of strings with group names, datas order should be same as group_names\n",
    "    colname: string, the category to compare \n",
    "    return tukeyhsd table result and stacked table \n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(group_names)):\n",
    "        df[group_names[i]] = datas[i]\n",
    "    stacked_df = df.stack().reset_index()\n",
    "    stacked_df = stacked_df.rename(\n",
    "        columns={'level_0': 'id', 'level_1': 'state', 0: colname})\n",
    "    return stacked_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tukey hsd for post anova with significance\n",
    "def tukey_hsd(stacked_df, colname):\n",
    "    '''\n",
    "    stacked_df: from table_transform, a stacked df \n",
    "    colname: string, the category to compare \n",
    "    return tukeyhsd table result and stacked table \n",
    "    '''\n",
    "    MultiComp = MultiComparison(stacked_df[colname],\n",
    "                                stacked_df['state'])\n",
    "    return MultiComp.tukeyhsd().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for DC, MD, VA with review_count\n",
    "# we knew it will be normal due to Central Limit Theorem \n",
    "DC_review = sample_category(DC,100,100000,'review_count')\n",
    "MD_review = sample_category(MD,100,100000,'review_count')\n",
    "VA_review = sample_category(VA,100,100000,'review_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df_review = table_transform([DC_review,MD_review,VA_review], ['DC','MD','VA'],colname='review_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=25515.202312377638, pvalue=0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance test\n",
    "stats.levene(DC_review,MD_review,VA_review)\n",
    "# variance is not equal \n",
    "# we will first use one way anova but be mindful of that due to same sample size\n",
    "# we will also perform welch's F test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=353339.2944923518, pvalue=0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(DC_review, MD_review, VA_review)\n",
    "# show significance with oneway anova "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>2</td>\n",
       "      <td>177911.775</td>\n",
       "      <td>526408.072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source  ddof1       ddof2           F  p-unc\n",
       "0  state      2  177911.775  526408.072    0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check with welch F test \n",
    "pingouin.welch_anova(dv='review_count', between='state',data=stacked_df_review)\n",
    "# same result as oneway anova "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "  <th>group1</th> <th>group2</th> <th>meandiff</th>  <th>p-adj</th>   <th>lower</th>     <th>upper</th>   <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>DC</td>     <td>MD</td>   <td>-113.2925</td> <td>0.001</td> <td>-113.6134</td> <td>-112.9717</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>DC</td>     <td>VA</td>    <td>-39.085</td>  <td>0.001</td> <td>-39.4059</td>  <td>-38.7642</td>   <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>MD</td>     <td>VA</td>    <td>74.2075</td>  <td>0.001</td>  <td>73.8866</td>   <td>74.5284</td>   <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for more information using tukey_hsd\n",
    "tukey_hsd(stacked_df_review,'review_count')\n",
    "# MD has the most traffic then VA then DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for DC, MD, VA with rating \n",
    "DC_rating = sample_category(DC,100,100000,'rating')\n",
    "MD_rating = sample_category(MD,100,100000,'rating')\n",
    "VA_rating = sample_category(VA,100,100000,'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.probplot(DC_rating, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(MD_rating, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(VA_rating, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=881.5471868374034, pvalue=0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance test\n",
    "stats.levene(DC_rating,MD_rating,VA_rating)\n",
    "# variance is not equal \n",
    "# we will first use one way anova but be mindful of that due to same sample size\n",
    "# we will also perform welch's F test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=320787.2190432029, pvalue=0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(DC_rating, MD_rating,VA_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked df for both tukey_hsd and welch F test\n",
    "stacked_df_rating = table_transform([DC_rating, MD_rating, VA_rating], [\n",
    "                                    'DC', 'MD', 'VA'], 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>2</td>\n",
       "      <td>199397.179</td>\n",
       "      <td>297075.601</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source  ddof1       ddof2           F  p-unc\n",
       "0  state      2  199397.179  297075.601    0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check with welch F test \n",
    "pingouin.welch_anova(dv='rating', between='state',data=stacked_df_rating)\n",
    "# same result as oneway anova "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "  <th>group1</th> <th>group2</th> <th>meandiff</th> <th>p-adj</th>  <th>lower</th>   <th>upper</th>  <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>DC</td>     <td>MD</td>    <td>-0.289</td>  <td>0.001</td> <td>-0.2899</td> <td>-0.2881</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>DC</td>     <td>VA</td>    <td>-0.0621</td> <td>0.001</td> <td>-0.063</td>  <td>-0.0612</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>MD</td>     <td>VA</td>    <td>0.2269</td>  <td>0.001</td>  <td>0.226</td>  <td>0.2278</td>   <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tukey_hsd(stacked_df_rating,'rating')\n",
    "# MD has highest rating then VA then DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check location correlation with most popular cuisines, ramen and bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rows helper function\n",
    "def split_rows(df, col1, col2, sep):\n",
    "    '''\n",
    "    input: \n",
    "    df: dataframe to use\n",
    "    col1 and col2 (use col2 to split )\n",
    "    return:\n",
    "    a df table with col1 as common col and col2 split into multiple rows\n",
    "    '''\n",
    "    series = [pd.Series(row[col1], row[col2].split(sep))\n",
    "              for _, row in df.iterrows()]\n",
    "    table = pd.concat(series).reset_index()\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = split_rows(df_location_price,'Lat', 'categories', '|')\n",
    "table = table.rename(columns = {'index': 'category', 0: 'Lat'})\n",
    "# join table \n",
    "mergedtable = pd.merge(df_location_price,table, on = 'Lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out only bars and ramen \n",
    "filtered_df = mergedtable[(mergedtable.category=='Bars')|(mergedtable.category =='Ramen')]\n",
    "# make into a count table between state and category \n",
    "counts = filtered_df.groupby(['state','category']).size().reset_index()\n",
    "# make into correct format for chisquare test \n",
    "chi_table= counts.pivot(index = 'state', columns='category', values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>Bars</th>\n",
       "      <th>Ramen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>221</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>143</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category  Bars  Ramen\n",
       "state                \n",
       "DC         221     46\n",
       "MD          61      8\n",
       "VA         143     19"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence is DC, MD, VA\n",
    "chi_array = np.array(chi_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[221,  46],\n",
       "       [ 61,   8],\n",
       "       [143,  19]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.039371664444074, 0.218780609974467, 2, array([[227.86144578,  39.13855422],\n",
       "        [ 58.88554217,  10.11445783],\n",
       "        [138.25301205,  23.74698795]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(chi_array)\n",
    "# chi2 is 3.03\n",
    "# p value is 0.218 > alpha (0.05)\n",
    "# dof = 2 \n",
    "# no depedency between location and ramen or bar \n",
    "# location doesn't seem to influence more ramen to be open in DC than MD and VA "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
